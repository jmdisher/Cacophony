package com.jeffdisher.cacophony.commands;

import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.PrintStream;
import java.nio.file.Files;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;

import com.eclipsesource.json.JsonArray;
import com.eclipsesource.json.JsonObject;
import com.jeffdisher.cacophony.Version;
import com.jeffdisher.cacophony.data.global.GlobalData;
import com.jeffdisher.cacophony.data.global.description.StreamDescription;
import com.jeffdisher.cacophony.data.global.index.StreamIndex;
import com.jeffdisher.cacophony.data.global.recommendations.StreamRecommendations;
import com.jeffdisher.cacophony.data.global.record.DataElement;
import com.jeffdisher.cacophony.data.global.record.ElementSpecialType;
import com.jeffdisher.cacophony.data.global.record.StreamRecord;
import com.jeffdisher.cacophony.data.global.records.StreamRecords;
import com.jeffdisher.cacophony.data.local.v1.FollowIndex;
import com.jeffdisher.cacophony.data.local.v1.FollowRecord;
import com.jeffdisher.cacophony.data.local.v1.FollowingCacheElement;
import com.jeffdisher.cacophony.data.local.v1.GlobalPrefs;
import com.jeffdisher.cacophony.data.local.v1.LocalIndex;
import com.jeffdisher.cacophony.logic.IConnection;
import com.jeffdisher.cacophony.logic.IEnvironment;
import com.jeffdisher.cacophony.logic.IEnvironment.IOperationLog;
import com.jeffdisher.cacophony.logic.LoadChecker;
import com.jeffdisher.cacophony.logic.LocalConfig;
import com.jeffdisher.cacophony.scheduler.FutureRead;
import com.jeffdisher.cacophony.scheduler.INetworkScheduler;
import com.jeffdisher.cacophony.types.CacophonyException;
import com.jeffdisher.cacophony.types.IpfsConnectionException;
import com.jeffdisher.cacophony.types.IpfsFile;
import com.jeffdisher.cacophony.types.IpfsKey;
import com.jeffdisher.cacophony.types.UsageException;
import com.jeffdisher.cacophony.utils.Assert;


/**
 * Walks the existing data in the local cache, creating and populating the existing directory with a static site
 * including all of this information.
 * This is a simple way to view everything prior to the dynamic content in the WebUI which will be added in version 2.0.
 */
public record HtmlOutputCommand(File _directory) implements ICommand
{
	@Override
	public void runInEnvironment(IEnvironment environment) throws CacophonyException
	{
		if (_directory.exists())
		{
			throw new UsageException("Directory already exists: " + _directory);
		}
		LocalConfig local = environment.loadExistingConfig();
		
		// We need the local index.
		LocalIndex localIndex = local.readLocalIndex();
		
		IOperationLog log = environment.logOperation("Generating static HTML output in " + _directory);
		
		// Create the connection before creating the directory.
		IConnection connection =  local.getSharedConnection();
		if (!_directory.mkdir())
		{
			throw new UsageException("Directory cannot be created: " + _directory);
		}
		
		// Write the static files in the directory.
		PrintStream generatedStream;
		try {
			_writeStaticFile(_directory, "index.html");
			_writeStaticFile(_directory, "prefs.html");
			_writeStaticFile(_directory, "utils.js");
			_writeStaticFile(_directory, "user.html");
			_writeStaticFile(_directory, "play.html");
			_writeStaticFile(_directory, "recommending.html");
			_writeStaticFile(_directory, "following.html");
			
			generatedStream = new PrintStream(new FileOutputStream(new File(_directory, "generated_db.js")));
		}
		catch (IOException e)
		{
			throw new UsageException(e.getMessage());
		}
		
		// Now, write the generated_db.js.
		INetworkScheduler scheduler = environment.getSharedScheduler(connection, localIndex.keyName());
		generatedStream.println("// Note that this file is generated by HtmlOutputCommand.");
		generatedStream.println();
		
		// DATA_common.
		JsonObject dataCommon = new JsonObject();
		IpfsKey ourPublicKey = scheduler.getPublicKey();
		dataCommon.set("publicKey", ourPublicKey.toPublicKey());
		generatedStream.println("var DATA_common = " + dataCommon.toString());
		generatedStream.println();
		
		// DATA_version.
		JsonObject dataVersion = new JsonObject();
		dataVersion.set("hash", Version.HASH);
		dataVersion.set("version", Version.TAG);
		generatedStream.println("var DATA_version = " + dataVersion.toString());
		generatedStream.println();
		
		// DATA_prefs.
		GlobalPrefs prefs = local.readSharedPrefs();
		JsonObject dataPrefs = new JsonObject();
		dataPrefs.set("edgeSize", prefs.videoEdgePixelMax());
		dataPrefs.set("followerCacheBytes", prefs.followCacheTargetBytes());
		generatedStream.println("var DATA_prefs = " + dataPrefs.toString());
		generatedStream.println();
		
		// We need to make this information from ourselves and everyone we are following.
		LoadChecker checker = new LoadChecker(scheduler, local.loadGlobalPinCache(), connection);
		
		// Load all the index objects since we walk it for a few operations.
		List<FutureKey<StreamIndex>> indices = new ArrayList<>();
		_startLoad(indices, checker, ourPublicKey, localIndex.lastPublishedIndex());
		FollowIndex followIndex = local.loadFollowIndex();
		for(FollowRecord record : followIndex)
		{
			_startLoad(indices, checker, record.publicKey(), record.lastFetchedRoot());
		}
		
		// DATA_userInfo.
		JsonObject dataUserInfo = new JsonObject();
		List<FutureKey<StreamDescription>> descriptions = _loadDescriptions(checker, indices);
		for (FutureKey<StreamDescription> future : descriptions)
		{
			JsonObject json = _populateJsonForDescription(checker, future.future.get());
			dataUserInfo.set(future.publicKey.toPublicKey(), json);
		}
		generatedStream.println("var DATA_userInfo = " + dataUserInfo.toString());
		generatedStream.println();
		
		// DATA_elements.
		JsonObject dataElements = new JsonObject();
		// Fetch the StreamRecords.
		List<FutureKey<StreamRecords>> streamRecords = _loadRecords(checker, indices);
		
		// Note that the elements in streamRecords are derived from ourselves and all FollowIndex elements, so we can walk them in the same order.
		Iterator<FutureKey<StreamRecords>> recordsIterator = streamRecords.iterator();
		// The first element is ourselves.
		_populateAllElementsFromUserRoot(checker, dataElements, null, recordsIterator.next().future.get());
		// The rest of the list is in-order with followIndex.
		for(FollowRecord record : followIndex)
		{
			Map<IpfsFile, FollowingCacheElement> elementsCachedForUser = Arrays.stream(record.elements()).collect(Collectors.toMap((e) -> e.elementHash(), (e) -> e));
			_populateAllElementsFromUserRoot(checker, dataElements, elementsCachedForUser, recordsIterator.next().future.get());
		}
		// These should end at the same time.
		Assert.assertTrue(!recordsIterator.hasNext());
		generatedStream.println("var DATA_elements = " + dataElements.toString());
		generatedStream.println();
		
		// DATA_userPosts.
		JsonObject dataUserPosts = new JsonObject();
		recordsIterator = streamRecords.iterator();
		_populatePostsForUser(checker, dataUserPosts, ourPublicKey, recordsIterator.next().future.get());
		for(FollowRecord record : followIndex)
		{
			_populatePostsForUser(checker, dataUserPosts, record.publicKey(), recordsIterator.next().future.get());
		}
		Assert.assertTrue(!recordsIterator.hasNext());
		generatedStream.println("var DATA_userPosts = " + dataUserPosts.toString());
		generatedStream.println();
		
		// DATA_recommended.
		// Load recommended list.
		List<FutureKey<StreamRecommendations>> recommendationsFutures = _loadRecommendations(checker, indices);
		JsonObject dataRecommended = new JsonObject();
		Iterator<FutureKey<StreamRecommendations>> recommendationsIterator = recommendationsFutures.iterator();
		_populateRecommendationsForUser(checker, dataRecommended, ourPublicKey, recommendationsIterator.next().future.get());
		for(FollowRecord record : followIndex)
		{
			_populateRecommendationsForUser(checker, dataRecommended, record.publicKey(), recommendationsIterator.next().future.get());
		}
		Assert.assertTrue(!recommendationsIterator.hasNext());
		generatedStream.println("var DATA_recommended = " + dataRecommended.toString());
		generatedStream.println();
		
		// DATA_following.
		JsonArray dataFollowing = new JsonArray();
		for(FollowRecord record : followIndex)
		{
			dataFollowing.add(record.publicKey().toPublicKey());
		}
		generatedStream.println("var DATA_following = " + dataFollowing.toString());
		generatedStream.println();
		generatedStream.close();
		
		log.finish("HTML interface generation complete!  Point your browser at: " + new File(_directory, "index.html").toURI());
	}


	private void _writeStaticFile(File directory, String fileName) throws IOException
	{
		String path = "/resources/site/" + fileName;
		InputStream stream = HtmlOutputCommand.class.getResourceAsStream(path);
		Files.copy(stream, new File(directory, fileName).toPath());
		stream.close();
	}

	private static void _startLoad(List<FutureKey<StreamIndex>> list, LoadChecker checker, IpfsKey publicKey, IpfsFile indexRoot)
	{
		FutureRead<StreamIndex> index = checker.loadCached(indexRoot, (byte[] data) -> GlobalData.deserializeIndex(data));
		list.add(new FutureKey<StreamIndex>(publicKey, index));
	}

	private static List<FutureKey<StreamDescription>> _loadDescriptions(LoadChecker checker, List<FutureKey<StreamIndex>> list) throws IpfsConnectionException
	{
		List<FutureKey<StreamDescription>> descriptions = new ArrayList<>();
		for (FutureKey<StreamIndex> future : list)
		{
			StreamIndex index = future.future.get();
			FutureRead<StreamDescription> description = checker.loadCached(IpfsFile.fromIpfsCid(index.getDescription()), (byte[] data) -> GlobalData.deserializeDescription(data));
			descriptions.add(new FutureKey<StreamDescription>(future.publicKey, description));
		}
		return descriptions;
	}

	private static JsonObject _populateJsonForDescription(LoadChecker checker, StreamDescription description)
	{
		JsonObject thisUser = new JsonObject();
		thisUser.set("name", description.getName());
		thisUser.set("description", description.getDescription());
		thisUser.set("userPicUrl", checker.getCachedUrl(IpfsFile.fromIpfsCid(description.getPicture())).toString());
		thisUser.set("email", description.getEmail());
		thisUser.set("website", description.getWebsite());
		return thisUser;
	}

	private static List<FutureKey<StreamRecords>> _loadRecords(LoadChecker checker, List<FutureKey<StreamIndex>> list) throws IpfsConnectionException
	{
		List<FutureKey<StreamRecords>> recordsList = new ArrayList<>();
		for (FutureKey<StreamIndex> future : list)
		{
			StreamIndex index = future.future.get();
			FutureRead<StreamRecords> records = checker.loadCached(IpfsFile.fromIpfsCid(index.getRecords()), (byte[] data) -> GlobalData.deserializeRecords(data));
			recordsList.add(new FutureKey<StreamRecords>(future.publicKey, records));
		}
		return recordsList;
	}

	private static void _populateAllElementsFromUserRoot(LoadChecker checker, JsonObject rootData, Map<IpfsFile, FollowingCacheElement> elementsCachedForUser, StreamRecords records) throws IpfsConnectionException
	{
		// We want to distinguish between records which are cached for this user and which ones aren't.
		// (in theory, multiple users could have an identical element only cached in some of them which could be
		//  displayed for all of them - we will currently ignore that case and only add the last entry).
		List<String> rawCids = records.getRecord();
		List<FutureRead<StreamRecord>> loads = new ArrayList<>();
		for (String rawCid : rawCids)
		{
			IpfsFile cid = IpfsFile.fromIpfsCid(rawCid);
			FutureRead<StreamRecord> future = checker.loadCached(cid, (byte[] data) -> GlobalData.deserializeRecord(data));
			loads.add(future);
		}
		Iterator<String> cidIterator = rawCids.iterator();
		for (FutureRead<StreamRecord> future : loads)
		{
			IpfsFile cid = IpfsFile.fromIpfsCid(cidIterator.next());
			StreamRecord record = future.get();
			JsonObject thisElt = new JsonObject();
			thisElt.set("name", record.getName());
			thisElt.set("description", record.getDescription());
			thisElt.set("publishedSecondsUtc", record.getPublishedSecondsUtc());
			thisElt.set("discussionUrl", record.getDiscussion());
			
			boolean isLocalUser = (null == elementsCachedForUser);
			boolean isCachedFollowee = !isLocalUser && elementsCachedForUser.containsKey(cid);
			// In either of these cases, we will have the data cached.
			boolean isCached = (isLocalUser || isCachedFollowee);
			thisElt.set("cached", isCached);
			IpfsFile thumbnailCid = null;
			IpfsFile videoCid = null;
			if (isLocalUser)
			{
				// In the local case, we want to look at the rest of the record and figure out what makes most sense since all entries will be pinned.
				List<DataElement> elements = record.getElements().getElement();
				thumbnailCid = _findThumbnail(elements);
				videoCid = _findLargestVideo(elements);
			}
			else if (isCachedFollowee)
			{
				// In this case, we want to just see what we recorded in the followee cache since that is what we pinned.
				FollowingCacheElement cachedElement = elementsCachedForUser.get(cid);
				thumbnailCid = cachedElement.imageHash();
				videoCid = cachedElement.leafHash();
			}
			if (isCached)
			{
				// However we found these, they are expected to be in the cache and they should be locally pinned.
				// Note that we can have at most one thumbnail and one video but both are optional and there could be an entry with neither.
				String thumbnailUrl = null;
				if (null != thumbnailCid)
				{
					Assert.assertTrue(checker.isCached(thumbnailCid));
					thumbnailUrl = checker.getCachedUrl(thumbnailCid).toString();
				}
				String videoUrl = null;
				if (null != videoCid)
				{
					Assert.assertTrue(checker.isCached(videoCid));
					videoUrl = checker.getCachedUrl(videoCid).toString();
				}
				
				thisElt.set("thumbnailUrl", thumbnailUrl);
				thisElt.set("videoUrl", videoUrl);
			}
			rootData.set(cid.toSafeString(), thisElt);
		}
	}

	private static void _populatePostsForUser(LoadChecker checker, JsonObject rootData, IpfsKey publicKey, StreamRecords records)
	{
		JsonArray array = new JsonArray();
		for (String rawCid : records.getRecord())
		{
			array.add(rawCid);
		}
		rootData.set(publicKey.toPublicKey(), array);
	}

	private static List<FutureKey<StreamRecommendations>> _loadRecommendations(LoadChecker checker, List<FutureKey<StreamIndex>> list) throws IpfsConnectionException
	{
		List<FutureKey<StreamRecommendations>> recommendationsList = new ArrayList<>();
		for (FutureKey<StreamIndex> future : list)
		{
			StreamIndex index = future.future.get();
			FutureRead<StreamRecommendations> recommendations = checker.loadCached(IpfsFile.fromIpfsCid(index.getRecommendations()), (byte[] data) -> GlobalData.deserializeRecommendations(data));
			recommendationsList.add(new FutureKey<StreamRecommendations>(future.publicKey, recommendations));
		}
		return recommendationsList;
	}

	private static void _populateRecommendationsForUser(LoadChecker checker, JsonObject rootData, IpfsKey publicKey,StreamRecommendations recommendations)
	{
		JsonArray array = new JsonArray();
		for (String rawCid : recommendations.getUser())
		{
			array.add(rawCid);
		}
		rootData.set(publicKey.toPublicKey(), array);
	}

	private static IpfsFile _findThumbnail(List<DataElement> elements)
	{
		IpfsFile thumbnailCid = null;
		for (DataElement leaf : elements)
		{
			IpfsFile leafCid = IpfsFile.fromIpfsCid(leaf.getCid());
			if (ElementSpecialType.IMAGE == leaf.getSpecial())
			{
				thumbnailCid = leafCid;
				break;
			}
		}
		return thumbnailCid;
	}

	private static IpfsFile _findLargestVideo(List<DataElement> elements)
	{
		IpfsFile videoCid = null;
		int largestEdge = 0;
		for (DataElement leaf : elements)
		{
			IpfsFile leafCid = IpfsFile.fromIpfsCid(leaf.getCid());
			if (leaf.getMime().startsWith("video/"))
			{
				int maxEdge = Math.max(leaf.getHeight(), leaf.getWidth());
				if (maxEdge > largestEdge)
				{
					videoCid = leafCid;
				}
			}
		}
		return videoCid;
	}


	private static record FutureKey<T>(IpfsKey publicKey, FutureRead<T> future)
	{
	}
}
